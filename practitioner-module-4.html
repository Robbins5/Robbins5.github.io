<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Practitioner Module 4 | Risk & Control Implications</title>
  <meta name="description" content="Practitioner Module 4 translates AI into risk and control categories aligned to COSO ERM and the IIA Global Internal Audit Standards." />
  <link rel="stylesheet" href="style.css" />
</head>

<body>

<header class="site-header">
  <div class="container header-inner">
    <div class="brand">
      <a class="brand-link" href="index.html">
        <div class="brand-title">The AI-Ready Audit</div>
        <div class="brand-tagline">Architecting Internal Audit for Intelligent Systems</div>
      </a>
    </div>

    <nav class="nav" aria-label="Primary">
      <a class="nav-link" href="index.html">Home</a>
      <a class="nav-link" href="practitioner-path.html">Practitioner Path</a>
      <a class="nav-link" href="executive-path.html">Executive Path</a>
      <a class="nav-link" href="about.html">About</a>
    </nav>
  </div>
</header>

<main>

<section class="hero" style="padding-top: 50px;">
  <div class="container hero-grid" style="grid-template-columns: 1fr;">
    <div class="hero-copy">
      <p class="pill">Practitioner Module 4</p>
      <h1 class="hero-title">Risk & Control Implications of AI</h1>
      <p class="hero-subtitle">
        AI governance must translate into risk categories and enforceable controls. 
        This module maps AI risk domains to COSO Internal Control and ERM components, 
        and aligns assurance expectations with the IIA Global Internal Audit Standards.
      </p>
    </div>
  </div>
</section>

<section class="section" style="padding-top:0;">
  <div class="container" style="max-width: 900px;">

    <div class="module-grid" style="grid-template-columns: repeat(3, minmax(0, 1fr)); gap: 12px; margin-bottom: 10px;">
      <a class="btn btn-secondary" href="practitioner-module-3.html">← Module 3</a>
      <a class="btn btn-secondary" href="practitioner-path.html">Practitioner Path</a>
      <a class="btn btn-primary" href="practitioner-module-5.html">Module 5 →</a>
    </div>

    <div class="module" style="margin-bottom: 16px;">
      <div class="module-kicker">Executive summary</div>
      <div class="module-title">What this module establishes</div>
      <div class="module-desc">
        AI risk is not a new silo. It cuts across existing risk domains: data integrity, access management, model risk, 
        operational resilience, compliance, and reporting reliability. Internal audit should evaluate AI through established 
        control frameworks — particularly COSO’s components (Control Environment, Risk Assessment, Control Activities, 
        Information & Communication, Monitoring Activities) and the IIA’s standards on governance, risk management, 
        and internal control effectiveness.
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container" style="max-width: 900px;">

    <h2 class="section-title">1. Data Risk</h2>
    <p>
      AI systems rely on data inputs. Poor-quality, biased, incomplete, or unauthorized data directly affect outcomes.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Data governance ownership and accountability</li>
      <li>Access controls aligned to least privilege</li>
      <li>Data classification and approved AI-accessible datasets</li>
      <li>Monitoring for unauthorized retrieval or sensitive data exposure</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Control Activities; Information & Communication  
      <br>
      <strong>IIA Alignment:</strong> Governance and Risk Management (IIA Global Internal Audit Standards – evaluating risk management processes and internal control design)
    </p>

    <h2 class="section-title" style="margin-top:40px;">2. Model Risk</h2>
    <p>
      AI models introduce probabilistic outputs. Risks include bias, hallucination, drift, and degradation over time.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Model validation prior to deployment</li>
      <li>Defined performance thresholds</li>
      <li>Ongoing drift monitoring</li>
      <li>Version control and change management procedures</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Risk Assessment; Monitoring Activities  
      <br>
      <strong>IIA Alignment:</strong> Internal Control and Assurance Effectiveness
    </p>

    <h2 class="section-title" style="margin-top:40px;">3. Access & Authorization Risk</h2>
    <p>
      AI systems often integrate with enterprise systems. Improper access can expose financial, HR, legal, or operational data.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Role-based access controls</li>
      <li>Segregation of duties considerations in AI-enabled workflows</li>
      <li>Approval workflows for tool enablement</li>
      <li>Periodic access review and recertification</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Control Activities  
      <br>
      <strong>IIA Alignment:</strong> Evaluating Control Effectiveness; IT Governance Oversight
    </p>

    <h2 class="section-title" style="margin-top:40px;">4. Output Integrity Risk</h2>
    <p>
      AI-generated content may influence decisions, reporting, compliance filings, or financial documentation.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Human-in-the-loop review requirements</li>
      <li>Confidence thresholds and documentation standards</li>
      <li>Clear labeling of AI-assisted outputs</li>
      <li>Review before external reporting or regulatory use</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Information & Communication  
      <br>
      <strong>IIA Alignment:</strong> Assurance Over Reporting Reliability and Governance Processes
    </p>

    <h2 class="section-title" style="margin-top:40px;">5. Operational Resilience Risk</h2>
    <p>
      AI dependency may create single points of failure or vendor reliance risk.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Vendor due diligence and third-party risk review</li>
      <li>Fallback procedures if AI systems fail</li>
      <li>Incident response planning specific to AI malfunction</li>
      <li>Testing of recovery procedures</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Risk Assessment; Monitoring Activities  
      <br>
      <strong>IIA Alignment:</strong> Governance & Risk Management Effectiveness
    </p>

    <h2 class="section-title" style="margin-top:40px;">6. Compliance & Ethical Risk</h2>
    <p>
      AI may implicate privacy laws, intellectual property rights, discrimination concerns, and industry regulations.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Legal review of AI deployment use cases</li>
      <li>Privacy impact assessments</li>
      <li>Bias testing and fairness evaluations</li>
      <li>Documentation of regulatory interpretations</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Control Environment; Risk Assessment  
      <br>
      <strong>IIA Alignment:</strong> Ethics, Integrity, and Governance Oversight
    </p>

    <h2 class="section-title" style="margin-top:40px;">7. Monitoring & Continuous Assurance</h2>
    <p>
      AI-enabled environments require ongoing oversight. Monitoring must shift from manual review toward automated detection of anomalies and risk signals.
    </p>

    <p><strong>Control Expectations:</strong></p>
    <ul style="margin-left:20px;">
      <li>Defined AI risk indicators (usage spikes, policy overrides, drift signals)</li>
      <li>Automated exception reporting</li>
      <li>Escalation workflows</li>
      <li>Board-level reporting when material thresholds are exceeded</li>
    </ul>

    <p>
      <strong>COSO Alignment:</strong> Monitoring Activities  
      <br>
      <strong>IIA Alignment:</strong> Ongoing Assurance and Reporting to the Board
    </p>

    <div class="module" style="margin-top:34px;">
      <div class="module-kicker">Next module</div>
      <div class="module-title">Module 5: Auditing AI-Enabled Workflows</div>
      <div class="module-desc">
        Module 5 moves from control categories to testing methodology: how to audit AI-assisted processes,
        what evidence to obtain, and how to evaluate control performance in dynamic environments.
      </div>
      <div style="margin-top:12px;">
        <a class="btn btn-primary" href="practitioner-module-5.html">Continue to Module 5 →</a>
      </div>
    </div>

    <div style="margin-top:26px;">
      <div class="module-grid" style="grid-template-columns: repeat(3, minmax(0, 1fr)); gap: 12px;">
        <a class="btn btn-secondary" href="practitioner-module-3.html">← Module 3</a>
        <a class="btn btn-secondary" href="practitioner-path.html">Practitioner Path</a>
        <a class="btn btn-primary" href="practitioner-module-5.html">Module 5 →</a>
      </div>
    </div>

  </div>
</section>

</main>

<footer class="footer">
  <div class="container footer-inner">
    <div>
      <div class="footer-brand">The AI-Ready Audit</div>
      <div class="footer-note">Thought leadership on internal audit strategy for intelligent systems.</div>
    </div>
  </div>
  <div class="container footer-bottom">
    <p>&copy; 2026 Nicole Heflin</p>
  </div>
</footer>

</body>
</html>
