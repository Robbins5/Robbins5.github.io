<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Practitioner Module | Standards Alignment in Intelligent Systems</title>
  <meta name="description" content="A practitioner module translating IIA standards and COSO expectations into practical internal audit oversight for AI-enabled operating models." />
  <link rel="stylesheet" href="style.css" />
</head>

<body>

<header class="site-header">
  <div class="container header-inner">
    <div class="brand">
      <a class="brand-link" href="index.html">
        <div class="brand-title">The AI-Ready Audit</div>
        <div class="brand-tagline">Architecting Internal Audit for Intelligent Systems</div>
      </a>
    </div>

    <nav class="nav" aria-label="Primary">
      <a class="nav-link" href="index.html">Home</a>
      <a class="nav-link" href="practitioner-path.html">Practitioner Path</a>
      <a class="nav-link" href="executive-path.html">Executive Path</a>
      <a class="nav-link" href="about.html">About</a>
    </nav>
  </div>
</header>

<main>

  <!-- Module Header -->
  <section class="hero" style="padding-top: 50px;">
    <div class="container hero-grid" style="grid-template-columns: 1fr;">
      <div class="hero-copy">
        <p class="pill">Practitioner Module</p>
        <h1 class="hero-title">Standards Alignment in Intelligent Systems</h1>
        <p class="hero-subtitle">
          AI does not invalidate internal audit standards. It makes them harder to execute without structural changes in approach.
          This module translates IIA expectations and COSO principles into practical oversight for AI-enabled operating models—
          where decisions move faster, evidence is less visible, and risk is introduced upstream.
        </p>
      </div>
    </div>
  </section>

  <!-- Module Nav (Top) + Executive Summary -->
  <section class="section" style="padding-top: 0;">
    <div class="container" style="max-width: 900px;">

      <div class="module-grid" style="grid-template-columns: repeat(3, minmax(0, 1fr)); gap: 12px; margin-bottom: 10px;">
        <a class="btn btn-secondary" href="practitioner-module-4.html">← Module 4</a>
        <a class="btn btn-secondary" href="practitioner-path.html">Practitioner Path</a>
        <a class="btn btn-primary" href="practitioner-module-5.html">Next: Execution →</a>
      </div>

      <div class="module" style="margin-bottom: 16px;">
        <div class="module-kicker">Executive summary</div>
        <div class="module-title">What this module establishes</div>
        <div class="module-desc">
          Internal audit’s mandate remains governance, risk management, and control assurance.
          What changes in AI-enabled operations is the shape of evidence, the timing of risk, and the need for monitoring to scale assurance.
          COSO still frames what “good control” looks like. The IIA standards still define audit’s role.
          The operating model must evolve so audit can evaluate intelligent systems with the same discipline used for financial and operational risk.
        </div>
      </div>

    </div>
  </section>

  <!-- Content -->
  <section class="section">
    <div class="container" style="max-width: 900px;">

      <h2 class="section-title">1. The standards aren’t changing — the operating environment is</h2>
      <p>
        In AI-enabled environments, outcomes can be influenced by tools that are not formally “systems of record.”
        A productivity assistant can shape a pricing narrative. A summarization tool can influence an HR conclusion.
        A customer-facing agent can affect service performance. In each case, the risk is introduced upstream, before traditional controls
        and reviews occur.
      </p>
      <p>
        The practical implication is that audit must be able to evaluate how decisions are formed, not just whether the final output is documented.
        This is the core of the operating model shift: governance and control assurance must follow the decision pathway.
      </p>

      <h2 class="section-title" style="margin-top: 40px;">2. COSO remains the backbone — AI changes how you validate it</h2>
      <p>
        COSO’s internal control components still apply directly:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li><strong>Control Environment:</strong> accountability, integrity, competence, and governance tone</li>
        <li><strong>Risk Assessment:</strong> identifying and analyzing risks as conditions change</li>
        <li><strong>Control Activities:</strong> policies and procedures that ensure objectives are achieved</li>
        <li><strong>Information & Communication:</strong> quality, relevance, and flow of information</li>
        <li><strong>Monitoring:</strong> evaluating whether controls operate as intended over time</li>
      </ul>
      <p style="margin-top: 10px;">
        AI changes the validation method. Traditional evidence artifacts may be incomplete or absent. Controls often require technical enforcement.
        Monitoring becomes structural because risk posture can change between audit cycles.
      </p>

      <div class="module" style="margin-top: 18px;">
        <div class="module-kicker">Practical translation</div>
        <div class="module-title">COSO “Monitoring” becomes the scaling mechanism</div>
        <div class="module-desc">
          In intelligent systems, monitoring is not a control afterthought. It is how organizations detect drift, misuse, and exceptions
          when decision-making accelerates and evidence becomes less static.
        </div>
      </div>

      <h2 class="section-title" style="margin-top: 40px;">3. The IIA standards still define audit’s role — but execution needs modernization</h2>
      <p>
        Internal audit is still expected to provide independent assurance over governance, risk management, and internal controls,
        and to communicate results clearly to oversight. In AI-enabled operating models, the standards do not require “AI expertise.”
        They require audit to remain effective as the environment changes.
      </p>
      <p>
        Practically, this means audit must:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li>Maintain objectivity while engaging earlier (upstream) in governance design</li>
        <li>Expand evidence expectations beyond documents to include system behavior and traceability</li>
        <li>Update methodology so assurance can scale (population-level testing, monitoring signals, exception discipline)</li>
        <li>Communicate AI-related risk in operational terms leadership can act on</li>
      </ul>

      <h2 class="section-title" style="margin-top: 40px;">4. Oversight reality: when executive leadership doubles as audit committee</h2>
      <p>
        In some enterprise structures, audit committee oversight is executive-led. That structure can be effective, but it changes how internal audit
        must operate. Governance maturity cannot depend on assumed independence. It must be made visible through disciplined reporting and measurable signals.
      </p>
      <p>
        In these environments, internal audit stays relevant by elevating clarity:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li><strong>Make risk measurable:</strong> define thresholds, indicators, and exception volumes</li>
        <li><strong>Make governance observable:</strong> ownership, guardrails, logging, escalation</li>
        <li><strong>Make outcomes operational:</strong> margin, forecast accuracy, service performance, customer impact</li>
      </ul>
      <p style="margin-top: 10px;">
        The standard is not “perfect governance.” The standard is “auditable governance.”
      </p>

      <h2 class="section-title" style="margin-top: 40px;">5. What changes in audit planning</h2>
      <p>
        AI requires internal audit to expand how it identifies risk and scopes work. Planning must include:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li><strong>AI touchpoint mapping:</strong> where AI influences decisions or execution within major processes</li>
        <li><strong>Decision pathway mapping:</strong> how conclusions are formed and where AI participates</li>
        <li><strong>Evidence strategy:</strong> what is logged, what is retained, and what audit can reconstruct</li>
        <li><strong>Monitoring strategy:</strong> what signals exist today and what signals must be designed</li>
      </ul>

      <div class="module" style="margin-top: 18px;">
        <div class="module-kicker">Scoping discipline</div>
        <div class="module-title">Ask “where does AI influence outcomes?” before “where is AI deployed?”</div>
        <div class="module-desc">
          A tool may not be formally “deployed” and still influence decisions daily. Audit planning should scope influence pathways,
          not just implementation announcements.
        </div>
      </div>

      <h2 class="section-title" style="margin-top: 40px;">6. What changes in fieldwork methodology</h2>
      <p>
        Fieldwork must evolve in three practical ways:
      </p>

      <h3 style="margin-top: 14px;">A. Walkthroughs expand to include AI influence</h3>
      <p>
        Walkthroughs must identify where AI is consulted, what data is referenced, what guardrails exist, and how outputs are reviewed.
        The purpose is not to audit the technology in isolation. The purpose is to validate that the process remains controlled.
      </p>

      <h3 style="margin-top: 14px;">B. Evidence expands to include traceability and behavior</h3>
      <p>
        Evidence in intelligent systems includes logs, prompts, outputs, version changes, and exception signals.
        If the organization cannot reconstruct AI influence for a decision, the process is not audit-ready.
      </p>

      <h3 style="margin-top: 14px;">C. Testing shifts toward population-level signals where risk is continuous</h3>
      <p>
        Sampling remains useful, but becomes less sufficient as AI increases variability and speed.
        Population-level testing and continuous monitoring allow audit to detect patterns that point-in-time testing can miss.
      </p>

      <h2 class="section-title" style="margin-top: 40px;">7. What changes in reporting</h2>
      <p>
        AI risk reporting should avoid technical abstraction. Leadership should receive clarity on:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li>Whether AI influences margin protection, forecasting accuracy, or service execution</li>
        <li>Whether governance is enforceable (not just documented)</li>
        <li>Whether monitoring signals exist and are reviewed</li>
        <li>Whether exceptions are escalated and resolved with discipline</li>
      </ul>
      <p style="margin-top: 10px;">
        In executive-led oversight structures, reporting discipline is what creates governance visibility. The goal is actionable clarity, not technical detail.
      </p>

      <h2 class="section-title" style="margin-top: 40px;">8. What skills audit teams must build (right-sized)</h2>
      <p>
        A mid-sized internal audit function supporting a Fortune-scale enterprise does not need everyone to be technical specialists.
        It does need role-appropriate capability:
      </p>
      <ul style="margin-left: 20px; margin-top: 10px;">
        <li><strong>All auditors:</strong> AI literacy, identifying AI influence, evidence discipline, exception reasoning</li>
        <li><strong>Managers:</strong> AI-aware walkthrough design, traceability evaluation, monitoring expectations</li>
        <li><strong>Senior managers:</strong> scope architecture, governance evaluation, cross-functional alignment</li>
        <li><strong>Director:</strong> governance visibility, executive reporting, capability roadmap, strategic positioning</li>
      </ul>

      <div class="module" style="margin-top: 34px;">
        <div class="module-kicker">Next module</div>
        <div class="module-title">Execution: Auditing AI-enabled workflows</div>
        <div class="module-desc">
          Next, we move from standards and expectations into fieldwork execution:
          walkthroughs, evidence, control evaluation, monitoring signals, and exception discipline—grounded in real operating constraints.
        </div>
        <div style="margin-top: 12px;">
          <a class="btn btn-primary" href="practitioner-module-5.html">Continue to Execution →</a>
        </div>
      </div>

      <!-- Bottom Nav -->
      <div style="margin-top: 26px;">
        <div class="module-grid" style="grid-template-columns: repeat(3, minmax(0, 1fr)); gap: 12px;">
          <a class="btn btn-secondary" href="practitioner-module-4.html">← Module 4</a>
          <a class="btn btn-secondary" href="practitioner-path.html">Practitioner Path</a>
          <a class="btn btn-primary" href="practitioner-module-5.html">Execution →</a>
        </div>
      </div>

    </div>
  </section>

</main>

<footer class="footer">
  <div class="container footer-inner">
    <div>
      <div class="footer-brand">The AI-Ready Audit</div>
      <div class="footer-note">Thought leadership on internal audit strategy for intelligent systems.</div>
    </div>
  </div>
  <div class="container footer-bottom">
    <p>&copy; 2026 Nicole Heflin</p>
  </div>
</footer>

</body>
</html>
